{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b6bb9a",
   "metadata": {},
   "source": [
    "Data: https://opus.nlpl.eu/opus-100.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5eb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df99b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class paths:\n",
    "    data = os.path.join('data', 'en-pl')\n",
    "    pl_test = os.path.join(data, 'opus.en-pl-test.pl')\n",
    "    en_test = os.path.join(data, 'opus.en-pl-test.en')\n",
    "    pl_dev = os.path.join(data, 'opus.en-pl-dev.pl')\n",
    "    en_dev = os.path.join(data, 'opus.en-pl-dev.en')\n",
    "    pl_train = os.path.join(data, 'opus.en-pl-train.pl')\n",
    "    en_train = os.path.join(data, 'opus.en-pl-train.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bde2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.vocab = {\n",
    "            '<unk>': 0,\n",
    "            '<pad>': 1,\n",
    "            '<sos>': 2,\n",
    "            '<eos>': 3\n",
    "        }\n",
    "        \n",
    "        self.build_vocab(data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        assert type(index) in [str, int], 'Index type must be string or int'\n",
    "        \n",
    "        if isinstance(index, str):\n",
    "            try:\n",
    "                return self.vocab[index]\n",
    "            \n",
    "            except KeyError:\n",
    "                return self.vocab['<unk>']\n",
    "        \n",
    "        elif isinstance(index, int):\n",
    "            try:\n",
    "                return list(self.vocab.keys())[list(self.vocab.values()).index(index)]\n",
    "            except (KeyError,ValueError):\n",
    "                return self[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def append_word(self, word):\n",
    "        if not word in self.vocab and word.isalpha():\n",
    "            self.vocab[word] = len(self)\n",
    "    \n",
    "    def build_vocab(self, data):\n",
    "        bag_of_words = sorted(list(set(data)))\n",
    "        \n",
    "        for word in bag_of_words:\n",
    "            self.append_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd751b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolEngDS(Dataset):\n",
    "    def __init__(self, pl_path, en_path):\n",
    "\n",
    "        self.data = {\n",
    "            'polish': self._load_data(pl_path),\n",
    "            'english': self._load_data(en_path)\n",
    "        }\n",
    "        \n",
    "        self.preprocessing()\n",
    "        \n",
    "        self.vocab_pl = Vocabulary(self.__flat_list(self.data['polish']))\n",
    "        self.vocab_en = Vocabulary(self.__flat_list(self.data['english']))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        pl, en = [text.split() for text in self.data.iloc[index].values]\n",
    "        \n",
    "        \n",
    "        return [self.vocab_pl[word] for word in pl], [self.vocab_en[word] for word in en]\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_data(path):\n",
    "        with open(path, 'r', encoding='UTF-8') as f:\n",
    "            data = f.read()\n",
    "        data = data.split('\\n')[:-1]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        preprocessed_data = {\n",
    "            'polish': [],\n",
    "            'english': []\n",
    "        }\n",
    "        \n",
    "        for i, (pl, en) in enumerate(zip(*self.data.values())):\n",
    "            preprocessed_data['polish'].append(self.__text_prep(pl))\n",
    "            preprocessed_data['english'].append(self.__text_prep(en))\n",
    "        \n",
    "        self.data = pd.DataFrame(preprocessed_data)\n",
    "   \n",
    "    @staticmethod\n",
    "    def __text_prep(text):\n",
    "        #remove punctuations\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.strip().lower()\n",
    "        text.split('/n')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def __flat_list(data):\n",
    "        data = [text.split() for text in data]\n",
    "        return list(itertools.chain.from_iterable(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90e1f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PolEngDS(paths.pl_test, paths.en_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac6870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poleng",
   "language": "python",
   "name": "poleng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
