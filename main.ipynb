{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b6bb9a",
   "metadata": {},
   "source": [
    "Data: https://opus.nlpl.eu/opus-100.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5eb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import itertools\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6c7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    epochs:int = 20\n",
    "    learning_rate:float = 3e-4\n",
    "    batch_size:int = 32\n",
    "    limit:int = 3500\n",
    "    max_length:int = 50\n",
    "    embed_size:int = 256\n",
    "    num_layers:int = 3\n",
    "    heads:int = 8\n",
    "    forward_expansion:int = 4\n",
    "    dropout:int = 0.15\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df99b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class paths:\n",
    "    data = os.path.join('data', 'en-pl')\n",
    "    pl_test = os.path.join(data, 'opus.en-pl-test.pl')\n",
    "    en_test = os.path.join(data, 'opus.en-pl-test.en')\n",
    "    pl_dev = os.path.join(data, 'opus.en-pl-dev.pl')\n",
    "    en_dev = os.path.join(data, 'opus.en-pl-dev.en')\n",
    "    pl_train = os.path.join(data, 'opus.en-pl-train.pl')\n",
    "    en_train = os.path.join(data, 'opus.en-pl-train.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bde2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.vocab = {\n",
    "            '<unk>': 0,\n",
    "            '<pad>': 1,\n",
    "            '<sos>': 2,\n",
    "            '<eos>': 3\n",
    "        }\n",
    "        \n",
    "        self.build_vocab(data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        assert type(index) in [str, int], 'Index type must be string or int'\n",
    "        \n",
    "        if isinstance(index, str):\n",
    "            try:\n",
    "                return self.vocab[index]\n",
    "            \n",
    "            except KeyError:\n",
    "                return self.vocab['<unk>']\n",
    "        \n",
    "        elif isinstance(index, int):\n",
    "            try:\n",
    "                return list(self.vocab.keys())[list(self.vocab.values()).index(index)]\n",
    "            except (KeyError,ValueError):\n",
    "                return self[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def append_word(self, word):\n",
    "        if not word in self.vocab and word.isalpha():\n",
    "            self.vocab[word] = len(self)\n",
    "    \n",
    "    def build_vocab(self, data):\n",
    "        bag_of_words = sorted(list(set(data)))\n",
    "        \n",
    "        for word in bag_of_words:\n",
    "            self.append_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd751b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolEngDS(Dataset):\n",
    "    def __init__(self, pl_path, en_path, limit=None):\n",
    "        \n",
    "        assert (limit >= 0 and type(limit) == int) or limit == None, 'Limit has to be integer, >= 0.' \n",
    "        \n",
    "        self.data = {\n",
    "            'polish': self._load_data(pl_path),\n",
    "            'english': self._load_data(en_path)\n",
    "        }\n",
    "        \n",
    "        if limit:\n",
    "            self.data['polish'] = self.data['polish'][:limit]\n",
    "            self.data['english'] = self.data['english'][:limit]\n",
    "            \n",
    "        self.preprocessing()\n",
    "        \n",
    "        self.vocab_pl = Vocabulary(self._flat_list(self.data['polish']))\n",
    "        self.vocab_en = Vocabulary(self._flat_list(self.data['english']))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        pl, en = [text.split() for text in self.data.iloc[index].values]\n",
    "        \n",
    "        pl = torch.IntTensor([vocab_pl['<sos>'], *[self.vocab_pl[word] for word in pl], vocab_pl['<eos>']])\n",
    "        en = torch.IntTensor([vocab_en['<sos>'], *[self.vocab_en[word] for word in en], vocab_en['<eos>']])\n",
    "        return pl, en \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_data(path):\n",
    "        with open(path, 'r', encoding='UTF-8') as f:\n",
    "            data = f.read()\n",
    "        data = data.split('\\n')[:-1]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        preprocessed_data = {\n",
    "            'polish': [],\n",
    "            'english': []\n",
    "        }\n",
    "        \n",
    "        for i, (pl, en) in enumerate(zip(*self.data.values())):\n",
    "            preprocessed_data['polish'].append(self._text_prep(pl))\n",
    "            preprocessed_data['english'].append(self._text_prep(en))\n",
    "        \n",
    "        self.data = pd.DataFrame(preprocessed_data)\n",
    "   \n",
    "    @staticmethod\n",
    "    def _text_prep(text):\n",
    "        #remove punctuations\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.strip().lower()\n",
    "        text.split('/n')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def _flat_list(data):\n",
    "        data = [text.split() for text in data]\n",
    "        return list(itertools.chain.from_iterable(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e1f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PolEngDS(\n",
    "    pl_path=paths.pl_train, \n",
    "    en_path=paths.en_train, \n",
    "    limit=config.limit\n",
    ")\n",
    "\n",
    "vocab_pl = train_data.vocab_pl\n",
    "vocab_en = train_data.vocab_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f863c",
   "metadata": {},
   "source": [
    "### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ac6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_pl = train_data.data['polish'].apply(lambda x: len(x.split())).values\n",
    "lens_en = train_data.data['english'].apply(lambda x: len(x.split())).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3f2aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile 98%: 25.019999999999982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile 98%: 30.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Polish texts - number of words per sequence')\n",
    "sns.histplot(lens_pl, bins=20)\n",
    "plt.show()\n",
    "print(F'Percentile 98%: {np.percentile(lens_pl, 98)}')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('English texts - number of words per sequence')\n",
    "sns.histplot(lens_en, bins=20)\n",
    "plt.show()\n",
    "print(F'Percentile 98%: {np.percentile(lens_en, 98)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508a478",
   "metadata": {},
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a79f9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb68022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(batch):\n",
    "    pl, en = [], []\n",
    "\n",
    "    for i, (pl_text, en_text) in enumerate(batch):\n",
    "        pl.append(pl_text)\n",
    "        en.append(en_text)\n",
    "\n",
    "    pl = pad_sequence(pl, batch_first=True, padding_value=vocab_pl['<pad>'])\n",
    "    en = pad_sequence(en, batch_first=True, padding_value=vocab_en['<pad>'])\n",
    "\n",
    "    return pl, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8115e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=config.batch_size, \n",
    "    collate_fn=pad_seq,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fbd64",
   "metadata": {},
   "source": [
    "**Based on**:\n",
    "    \n",
    "    - https://arxiv.org/pdf/1706.03762.pdf\n",
    "    - https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n",
    "    - https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py\n",
    "    - https://medium.com/@monimoyd/step-by-step-machine-translation-using-transformer-and-multi-head-attention-96435675be75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6c4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder:\n",
    "    def __init__(self, embed_size, n=10000):\n",
    "        self.embed_size = embed_size\n",
    "        self.n = n\n",
    "        \n",
    "    def positional_encoding(self, seq_len):\n",
    "        n = torch.IntTensor([self.n])\n",
    "        d = self.embed_size\n",
    "\n",
    "        pos_enc = torch.zeros((seq_len, d))\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            for i in range(int(d/2)):\n",
    "                p = torch.pow(n, 2*i/d)\n",
    "                \n",
    "                pos_enc[j, 2*i] = torch.sin(j/p)\n",
    "                pos_enc[j, 2*i+1] = torch.cos(j/p)\n",
    "\n",
    "        return pos_enc.unsqueeze(1)\n",
    "    \n",
    "    def __call__(self, seq_len):\n",
    "        return self.positional_encoding(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3803a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        \n",
    "        assert self.head_dim * self.heads == self.embed_size, 'Embed size needs to be divisible by heads'\n",
    "        \n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        \n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "        \n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        N = queries.shape[0]\n",
    "        values_len, keys_len, queries_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "        \n",
    "        # Split into self.heads number of heads\n",
    "        values = values.reshape(N, values_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, keys_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, queries_len, self.heads, self.head_dim)\n",
    "        \n",
    "        # values shape after: (N, self.heads, values_len, self.head_dim)\n",
    "        values = self.values(values).permute(0, 2, 1, 3) \n",
    "        \n",
    "        # keys shape after: (N, self.heads, self.head_dim, keys_len)\n",
    "        keys = self.keys(keys).permute(0, 2, 3, 1)\n",
    "        \n",
    "        # queries shape after: (N, self.heads, queries_len, self.head_dim)\n",
    "        queries = self.queries(queries).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # e shape after: (N, self.heads, queries_len, keys_len)\n",
    "        e = (queries @ keys) / (self.embed_size**(1/2))\n",
    "        \n",
    "        if mask is not None:\n",
    "            # if mask at same point is 0 - shutdown this point - set to -inf, in softmax it will be 0\n",
    "            e = e.masked_fill(mask == 0, -1e20)\n",
    "        \n",
    "        attention = torch.softmax(e, dim=3)\n",
    "\n",
    "        # out shape after: (N, self.heads, queries_len, self.head_dim)\n",
    "        out = attention @ values\n",
    "\n",
    "        out = out.reshape(N, queries_len, self.heads*self.head_dim)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "169166ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, embed_size, forward_expansion, dropout):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(embed_size, embed_size*forward_expansion)\n",
    "        self.fc_2 = nn.Linear(embed_size*forward_expansion, embed_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.fc_1(x))\n",
    "        x = self.dropout(self.fc_2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce93a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        \n",
    "        self.norm_1 = nn.LayerNorm(embed_size)\n",
    "        self.norm_2 = nn.LayerNorm(embed_size)\n",
    "        \n",
    "        self.feed_forward = FeedForwardNetwork(embed_size, forward_expansion, dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        attention = self.attention(values, keys, queries, mask)\n",
    "        \n",
    "        x = self.dropout(self.norm_1(attention + queries))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm_2(forward + x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58ce0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length,\n",
    "        device\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "        self.position_encoding = PositionalEncoder(embed_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "                \n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        out = self.dropout(\n",
    "            (self.word_embedding(x) + self.position_encoding(seq_len).to(self.device))\n",
    "        )\n",
    "\n",
    "        # In the Encoder the query, key, value are all the same, in the decoder it will change. \n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f958f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.attention = SelfAttention(embed_size, heads=heads)\n",
    "        self.transformer_block = Block(\n",
    "            embed_size, heads, forward_expansion, dropout\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82054974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trg_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length,\n",
    "        device\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "        self.position_encoding = PositionalEncoder(embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        x = self.dropout(\n",
    "            (self.word_embedding(x) + self.position_encoding(seq_len).to(self.device))\n",
    "        )\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9cc5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        embed_size=512,\n",
    "        num_layers=6,\n",
    "        heads=8,\n",
    "        forward_expansion=4,\n",
    "        dropout=0,\n",
    "        max_length=100,\n",
    "        device='cpu'\n",
    "    ):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "            device\n",
    "        ).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "            device\n",
    "        ).to(device)\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for mod in self.modules():\n",
    "            if isinstance(mod, (nn.Linear, nn.Embedding)):\n",
    "                torch.nn.init.normal_(mod.weight, mean=0.0, std=0.02)\n",
    "\n",
    "                if isinstance(mod, nn.Linear) and mod.bias is not None:\n",
    "                    torch.nn.init.zeros_(mod.bias)\n",
    "\n",
    "            elif isinstance(mod, nn.LayerNorm):\n",
    "                torch.nn.init.zeros_(mod.bias)\n",
    "                torch.nn.init.ones_(mod.weight)\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        return sum(par.numel() for par in self.parameters())\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        # mask only vocab['<pad>'], because it shouldn't have an effect on output result\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        # (N, 1, 1, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        # mask next words during decoding, decoder shouldn't have access to them \n",
    "        N, trg_len = trg.shape\n",
    "        \n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "            N, 1, trg_len, trg_len\n",
    "        )\n",
    "\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        \n",
    "        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403cce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0ab637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    src_vocab_size=len(vocab_pl),\n",
    "    trg_vocab_size=len(vocab_en),\n",
    "    src_pad_idx=vocab_pl['<pad>'],\n",
    "    trg_pad_idx=vocab_en['<pad>'],\n",
    "    embed_size=config.embed_size,\n",
    "    num_layers=config.num_layers,\n",
    "    heads=config.heads,\n",
    "    forward_expansion=config.forward_expansion,\n",
    "    dropout=config.dropout,\n",
    "    max_length=config.max_length,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35288472",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_en['<pad>'])\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c57714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jmisilo (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.14 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jmisilo/PolEng%20translation%20-%201649851057.840742/runs/ffcsf3sn\" target=\"_blank\">happy-moon-1</a></strong> to <a href=\"https://wandb.ai/jmisilo/PolEng%20translation%20-%201649851057.840742\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jmisilo/PolEng%20translation%20-%201649851057.840742/runs/ffcsf3sn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x212028288b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=f'PolEng translation - {time.time()}', \n",
    "    config=config.__dict__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e2f6432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6190c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, epoch, device=device):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    t0 = time.time()\n",
    "    t_batch = t0\n",
    "    \n",
    "    for batch_idx, (src, trg) in enumerate(loader):\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        scores = model(src, trg[:, :-1])\n",
    "        \n",
    "        loss = criterion(\n",
    "            scores.reshape(-1, scores.shape[2]), \n",
    "            trg[:, 1:].reshape(-1).type(torch.long)\n",
    "        )\n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1) % int(len(loader) / 5) == 0:\n",
    "            print('Epoch: {epoch}, batch: {batch_idx}/{no_batches}, loss: {loss:.3f}, time: {t:.2f}'.format(\n",
    "                epoch=epoch+1,\n",
    "                batch_idx=batch_idx,\n",
    "                no_batches=len(loader),\n",
    "                loss=sum(losses)/len(losses),\n",
    "                t=time.time()-t_batch\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            t_batch = time.time()\n",
    "        \n",
    "    loss = sum(losses) / len(losses)\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    print('Epoch: {epoch}, loss: {loss:.3f}, time: {t:.2f}'.format(\n",
    "        epoch=epoch+1, \n",
    "        loss=loss, \n",
    "        t=time.time()-t0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55afc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    l = train_epoch(model, train_loader, epoch)\n",
    "    loss.append(l)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_sd': model.state_dict(),\n",
    "        'optimizer_sd': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "       }, f'./models/checkpoint-{epoch}.pt')\n",
    "    \n",
    "    wandb.log({\n",
    "        'loss': l\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48aab17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(\n",
    "    sentence_pl, \n",
    "    model=model, \n",
    "    vocab_pl=vocab_pl, \n",
    "    vocab_en=vocab_en, \n",
    "    device=device, \n",
    "    max_length=50\n",
    "):\n",
    "    \n",
    "    sentence_pl = [vocab_pl[word] for word in PolEngDS._text_prep(sentence_pl).split()]\n",
    "    sentence_pl = [vocab_pl['<sos>'], *sentence_pl, vocab_pl['<eos>']]\n",
    "    sentence_pl = torch.IntTensor(sentence_pl).unsqueeze(0)\n",
    "    \n",
    "    print(sentence_pl)\n",
    "    \n",
    "    outputs = [vocab_en['<sos>']]\n",
    "    \n",
    "    model.eval()\n",
    "    for i in range(max_length):\n",
    "        sentence_en = torch.IntTensor(outputs).unsqueeze(0)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_pl, sentence_en)\n",
    "            \n",
    "        prediction = output.argmax(2)[:, -1].item()\n",
    "        outputs.append(prediction)\n",
    "        print(outputs)\n",
    "        if prediction == vocab_en['<eos>']:\n",
    "            break\n",
    "    \n",
    "    sentence_en = [vocab_en[word] for word in outputs]\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return sentence_en[1:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poleng",
   "language": "python",
   "name": "poleng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
